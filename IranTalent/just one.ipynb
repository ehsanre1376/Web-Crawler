{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "url = r\"https://www.irantalent.com\"\n",
    "site = requests.get(url + \"/companies\")\n",
    "soup = BeautifulSoup(site.text, \"html.parser\")\n",
    "with open(r\"C:\\Users\\EHSANRE\\OneDrive\\Web Crawler\\Page Number.txt\") as my_file:\n",
    "    n = int(my_file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_page():\n",
    "    driver = webdriver.Edge()\n",
    "    driver.get(url + \"/companies\")\n",
    "    show_more_button = driver.find_element(\n",
    "        By.CSS_SELECTOR,\n",
    "        \"#companies-brands-list > div > div.d-flex.align-items-center.pagination-wrapper > button.page.action-next-page.flipArrowKeys\",\n",
    "    )\n",
    "\n",
    "    show_more_button.click()\n",
    "def read_web(Surl):\n",
    "    Ssite = requests.get(Surl)\n",
    "    Ssoup = BeautifulSoup(Ssite.text, \"html.parser\")\n",
    "    # Site---------------\n",
    "    courses = Ssoup.select(\n",
    "        \"body > app-root > div > div > div > div > company-branding > div > div.row.d-flex.flex-wrap > div.col-md-9.col-xs-12 > brand-overview > div > form > div.card-section.company-information.padding-top-16.ng-untouched.ng-pristine.ng-valid > div > div > div > div > div.col-md-7.col-xs-6 > a\"\n",
    "    )\n",
    "    siteLink = courses[0].get(\"href\")\n",
    "    # CEO-------------------\n",
    "    courses = Ssoup.select(\n",
    "    \"body > app-root > div > div > div > div > company-branding > div > div.row.d-flex.flex-wrap > div.col-md-9.col-xs-12 > brand-overview > div > form > div.card-section.company-information.padding-top-16.ng-untouched.ng-pristine.ng-valid > div > div > div > div > div.col-md-7.col-xs-6 > p\"\n",
    "    )\n",
    "\n",
    "    ceo=courses[0].text.strip()\n",
    "    # Date--------------------------------\n",
    "    courses = Ssoup.select(\n",
    "    \"body > app-root > div > div > div:nth-child(2) > div > company-branding > div > div.row.d-flex.flex-wrap > div.col-md-9.col-xs-12 > brand-overview > div > form > div.card-section.company-information.padding-top-16.ng-untouched.ng-pristine.ng-valid > div > div > div:nth-child(1) > div:nth-child(3) > div.col-md-7.col-xs-6 > p\"\n",
    "    )\n",
    "\n",
    "    date=courses[0].text.strip()\n",
    "    # address---------------\n",
    "    courses = Ssoup.select(\n",
    "    \"body > app-root > div > div > div:nth-child(2) > div > company-branding > div > div.row.d-flex.flex-wrap > div.col-md-9.col-xs-12 > brand-overview > div > form > div.card-section.company-information.padding-top-16.ng-untouched.ng-pristine.ng-valid > div > div > div:nth-child(2) > div:nth-child(2) > div.col-md-7.col-xs-6 > p\"\n",
    "    )\n",
    "\n",
    "    address=courses[0].text.strip()\n",
    "    # Location----------------\n",
    "    courses = Ssoup.select(\n",
    "    \"body > app-root > div > div > div:nth-child(2) > div > company-branding > div > div.row.d-flex.flex-wrap > div.col-md-9.col-xs-12 > brand-overview > div > form > div.card-section.company-information.padding-top-16.ng-untouched.ng-pristine.ng-valid > div > div > div:nth-child(2) > div:nth-child(1) > div.col-md-7.col-xs-6 > p\"\n",
    ")\n",
    "\n",
    "    Location=courses[0].text.strip().replace(\",\", \"\")\n",
    "    return siteLink, ceo, date, address, Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              title                                              Links  \\\n",
      "0  خدمات انفورماتیک  https://www.irantalent.com/company/informatics...   \n",
      "\n",
      "                                   industrial           personels  \\\n",
      "0  فناوری اطلاعات، خدمات اینترنتی و نرم افزار  500 کارمند به بالا   \n",
      "\n",
      "               siteLink ceo  date                 address Location  \n",
      "0  http://www.isc.co.ir      1993  تهران، خیابان میرداماد    تهران  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'with open(\"Page Number.txt\", \"w\") as my_file:\\n    my_file.write(str(i))\\nchange_page()'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loop for every page\n",
    "# df = pd.read_excel(r\"C:\\Users\\EHSANRE\\OneDrive\\Web Crawler\\IranTalent.xlsx\")\n",
    "titles\t=Links\t=industrial=\tpersonels\t=siteLink\t=ceo=\tdate\t=address\t=Location=[]\n",
    "\n",
    "\n",
    "url = r\"https://www.irantalent.com\"\n",
    "site = requests.get(url + \"/companies\")\n",
    "soup = BeautifulSoup(site.text, \"html.parser\")\n",
    "# titles---------------------------------------\n",
    "titles = soup.select(\"div.card-title.d-flex.flex-column.padding-all-16 > p[title]\")\n",
    "\n",
    "# Extract the title attribute from each p element\n",
    "titles = [elem[\"title\"].strip() for elem in titles][0]\n",
    "# Links----------------------------------------\n",
    "courses = soup.select(\n",
    "\"body > app-root > div > div > div > div > it-company-list > div > div > div.container.w-100.padding-x-12.mobile-padding-x-0.main-wrapper > div.padding-y-24.mobile-padding-y-12 > div > div > div > a \"\n",
    ")\n",
    "overviewLink = [url + link.get(\"href\") for link in courses][0]\n",
    "# industrial--------------------------------\n",
    "courses = soup.select(\n",
    "\"body > app-root > div > div > div > div > it-company-list > div > div > div.container.w-100.padding-x-12.mobile-padding-x-0.main-wrapper > div.padding-y-24.mobile-padding-y-12 > div > div > div > a > div.padding-x-16.d-flex.text-decoration-none > p.font-weight-500.font-12.color-gray.margin-bottom-16.text-ellipsis.max-w-50.margin-right-8\"\n",
    ")\n",
    "\n",
    "industrial = [industrial.text.strip().replace(\"\\u200c\", \" \") for industrial in courses][0]\n",
    "# personels------------------------------\n",
    "courses = soup.select(\n",
    "\"body > app-root > div > div > div > div > it-company-list > div > div > div.container.w-100.padding-x-12.mobile-padding-x-0.main-wrapper > div.padding-y-24.mobile-padding-y-12 > div > div > div > a > div.padding-x-16.d-flex.text-decoration-none > p.d-flex.font-weight-500.font-12.color-gray.margin-bottom-16.max-w-50\"\n",
    ")\n",
    "\n",
    "\n",
    "personels = [personels.text.strip() for personels in courses][0]\n",
    "\n",
    "siteLink, ceo, date, address, Location = read_web(overviewLink)\n",
    "data = pd.DataFrame(\n",
    "    {\n",
    "        \"title\": titles,\n",
    "        \"Links\": overviewLink,\n",
    "        \"industrial\": industrial,\n",
    "        \"personels\": personels,\n",
    "        \"siteLink\": siteLink,\n",
    "        \"ceo\": ceo,\n",
    "        \"date\": date,\n",
    "        \"address\": address,\n",
    "        \"Location\": Location,\n",
    "    },\n",
    "    index=[0],\n",
    ")\n",
    "\n",
    "print(data)\n",
    "data.to_excel(\"output.xlsx\")\n",
    "# df.append(data)\n",
    "# appended_data.to_excel(r'C:\\Users\\EHSANRE\\OneDrive\\Web Crawler\\IranTalent.xlsx', index=False)\n",
    "\"\"\"with open(\"Page Number.txt\", \"w\") as my_file:\n",
    "    my_file.write(str(i))\n",
    "change_page()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import aiohttp\n",
    "import asyncio\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "async def fetch(session, url):\n",
    "    async with session.get(url) as response:\n",
    "        return await response.text()\n",
    "\n",
    "\n",
    "async def main():\n",
    "    url = r\"https://www.irantalent.com\"\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        html = await fetch(session, url + \"/companies\")\n",
    "        soup = BeautifulSoup(html, \"html.parser\")\n",
    "        # Your scraping code here...\n",
    "\n",
    "\n",
    "# Run the main function\n",
    "loop = asyncio.get_event_loop()\n",
    "loop.run_until_complete(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "url = r\"https://www.irantalent.com\"\n",
    "site = requests.get(url + \"/companies\")\n",
    "soup = BeautifulSoup(site.text, \"html.parser\")\n",
    "\n",
    "def read_web(Surl):\n",
    "    Ssite = requests.get(Surl)\n",
    "    Ssoup = BeautifulSoup(Ssite.text, \"html.parser\")\n",
    "    # Site---------------\n",
    "    courses = Ssoup.select(\n",
    "        \"body > app-root > div > div > div > div > company-branding > div > div.row.d-flex.flex-wrap > div.col-md-9.col-xs-12 > brand-overview > div > form > div.card-section.company-information.padding-top-16.ng-untouched.ng-pristine.ng-valid > div > div > div > div > div.col-md-7.col-xs-6 > a\"\n",
    "    )\n",
    "    siteLink = courses[0].get(\"href\")\n",
    "    return siteLink\n",
    "\n",
    "\n",
    "address = siteLink = []\n",
    "\n",
    "\n",
    "url = r\"https://www.irantalent.com\"\n",
    "site = requests.get(url + \"/companies\")\n",
    "soup = BeautifulSoup(site.text, \"html.parser\")\n",
    "\n",
    "# Links----------------------------------------\n",
    "courses = soup.select(\n",
    "    \"body > app-root > div > div > div > div > it-company-list > div > div > div.container.w-100.padding-x-12.mobile-padding-x-0.main-wrapper > div.padding-y-24.mobile-padding-y-12 > div > div > div > a \"\n",
    ")\n",
    "overviewLink = [url + link.get(\"href\") for link in courses][0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "address= [read_web(wLink) for wlink in overviewLink]\n",
    "data = pd.DataFrame(\n",
    "    {\n",
    "        \n",
    "        \"Links\": overviewLink,\n",
    "        \n",
    "        \"address\": address,\n",
    "        \n",
    "    },\n",
    "    index=[0],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import aiohttp\n",
    "import asyncio\n",
    "from bs4 import BeautifulSoup\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import pandas as pd\n",
    "\n",
    "url = r\"https://www.irantalent.com\"\n",
    "\n",
    "\n",
    "async def read_web(session, Surl):\n",
    "    async with session.get(Surl) as Ssite:\n",
    "        text = await Ssite.text()\n",
    "        Ssoup = BeautifulSoup(text, \"html.parser\")\n",
    "        courses = Ssoup.select(\n",
    "            \"body > app-root > div > div > div > div > company-branding > div > div.row.d-flex.flex-wrap > div.col-md-9.col-xs-12 > brand-overview > div > form > div.card-section.company-information.padding-top-16.ng-untouched.ng-pristine.ng-valid > div > div > div > div > div.col-md-7.col-xs-6 > a\"\n",
    "        )\n",
    "        siteLink = courses[0].get(\"href\")\n",
    "        return siteLink\n",
    "\n",
    "\n",
    "async def main():\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        site = await session.get(url + \"/companies\")\n",
    "        text = await site.text()\n",
    "        soup = BeautifulSoup(text, \"html.parser\")\n",
    "\n",
    "        courses = soup.select(\n",
    "            \"body > app-root > div > div > div > div > it-company-list > div > div > div.container.w-100.padding-x-12.mobile-padding-x-0.main-wrapper > div.padding-y-24.mobile-padding-y-12 > div > div > div > a \"\n",
    "        )\n",
    "        overviewLink = [url + link.get(\"href\") for link in courses][0]\n",
    "\n",
    "        with ThreadPoolExecutor() as executor:\n",
    "            loop = asyncio.get_event_loop()\n",
    "            futures = [\n",
    "                loop.run_in_executor(executor, read_web, session, wLink)\n",
    "                for wLink in overviewLink\n",
    "            ]\n",
    "            address = await asyncio.gather(*futures)\n",
    "\n",
    "        data = pd.DataFrame(\n",
    "            {\n",
    "                \"Links\": overviewLink,\n",
    "                \"address\": address,\n",
    "            },\n",
    "            index=[0],\n",
    "        )\n",
    "\n",
    "\n",
    "# Run the main function\n",
    "asyncio.run(main())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
